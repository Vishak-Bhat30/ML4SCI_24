{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2194e74",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-24T12:12:56.418397Z",
     "iopub.status.busy": "2024-03-24T12:12:56.417335Z",
     "iopub.status.idle": "2024-03-24T12:13:06.179548Z",
     "shell.execute_reply": "2024-03-24T12:13:06.178332Z"
    },
    "papermill": {
     "duration": 9.771845,
     "end_time": "2024-03-24T12:13:06.182203",
     "exception": false,
     "start_time": "2024-03-24T12:12:56.410358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix ,roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import Linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b131bf07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:06.194459Z",
     "iopub.status.busy": "2024-03-24T12:13:06.193890Z",
     "iopub.status.idle": "2024-03-24T12:13:33.475362Z",
     "shell.execute_reply": "2024-03-24T12:13:33.473950Z"
    },
    "papermill": {
     "duration": 27.291393,
     "end_time": "2024-03-24T12:13:33.478949",
     "exception": false,
     "start_time": "2024-03-24T12:13:06.187556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\r\n",
      "  Downloading torch_geometric-2.5.2-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.11.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\r\n",
      "Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.5.2\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ba689c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:33.494030Z",
     "iopub.status.busy": "2024-03-24T12:13:33.493577Z",
     "iopub.status.idle": "2024-03-24T12:13:35.314601Z",
     "shell.execute_reply": "2024-03-24T12:13:35.313637Z"
    },
    "papermill": {
     "duration": 1.831626,
     "end_time": "2024-03-24T12:13:35.317087",
     "exception": false,
     "start_time": "2024-03-24T12:13:33.485461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7613009b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:35.332875Z",
     "iopub.status.busy": "2024-03-24T12:13:35.331769Z",
     "iopub.status.idle": "2024-03-24T12:13:36.503942Z",
     "shell.execute_reply": "2024-03-24T12:13:36.502905Z"
    },
    "papermill": {
     "duration": 1.183396,
     "end_time": "2024-03-24T12:13:36.506656",
     "exception": false,
     "start_time": "2024-03-24T12:13:35.323260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55613541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:36.520526Z",
     "iopub.status.busy": "2024-03-24T12:13:36.520129Z",
     "iopub.status.idle": "2024-03-24T12:13:53.775156Z",
     "shell.execute_reply": "2024-03-24T12:13:53.773778Z"
    },
    "papermill": {
     "duration": 17.265149,
     "end_time": "2024-03-24T12:13:53.777995",
     "exception": false,
     "start_time": "2024-03-24T12:13:36.512846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25\n",
    "\n",
    "# List of Parquet file paths\n",
    "file_paths = [\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file path\n",
    "for file_path in file_paths:\n",
    "    # Create a Parquet file reader object\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    \n",
    "    # Determine the total number of rows in the file\n",
    "    total_rows = parquet_file.metadata.num_rows\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = total_rows // chunk_size + (1 if total_rows % chunk_size else 0)\n",
    "    \n",
    "    # Loop over the file in chunks\n",
    "    for chunk_index in range(num_chunks):\n",
    "        # Read a chunk of rows from the file\n",
    "        chunk = parquet_file.read_row_group(chunk_index, columns=None)\n",
    "        df = chunk.to_pandas()\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3db2363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:53.792682Z",
     "iopub.status.busy": "2024-03-24T12:13:53.792252Z",
     "iopub.status.idle": "2024-03-24T12:13:53.797966Z",
     "shell.execute_reply": "2024-03-24T12:13:53.796860Z"
    },
    "papermill": {
     "duration": 0.015544,
     "end_time": "2024-03-24T12:13:53.800333",
     "exception": false,
     "start_time": "2024-03-24T12:13:53.784789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_3d(arr):\n",
    "    vishak=[]\n",
    "    for i in range (0,3):\n",
    "        vis=np.stack(np.stack(arr)[i],axis=-1)\n",
    "        vishak.append(vis)\n",
    "    vishak=np.array(vishak)\n",
    "    return vishak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163b64d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:53.814380Z",
     "iopub.status.busy": "2024-03-24T12:13:53.813988Z",
     "iopub.status.idle": "2024-03-24T12:13:58.342547Z",
     "shell.execute_reply": "2024-03-24T12:13:58.341310Z"
    },
    "papermill": {
     "duration": 4.538767,
     "end_time": "2024-03-24T12:13:58.345201",
     "exception": false,
     "start_time": "2024-03-24T12:13:53.806434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"X_jets\"]  = data[\"X_jets\"].apply(to_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d0e320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.359500Z",
     "iopub.status.busy": "2024-03-24T12:13:58.359107Z",
     "iopub.status.idle": "2024-03-24T12:13:58.371120Z",
     "shell.execute_reply": "2024-03-24T12:13:58.369814Z"
    },
    "papermill": {
     "duration": 0.021879,
     "end_time": "2024-03-24T12:13:58.373592",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.351713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_graph(image, patch_size=25, n_neighbors=15):\n",
    "        \"\"\"\n",
    "        Convert an image to a graph of its 5x5 patches.\n",
    "\n",
    "        Parameters:\n",
    "        - image: A (125, 125, 3) numpy array.\n",
    "        - patch_size: Size of the square patches (default 5).\n",
    "        - n_neighbors: Number of neighbors for KNN (default 5).\n",
    "\n",
    "        Returns:\n",
    "        - nodes: An array of node features.\n",
    "        - edges: A list of tuples (i, j, mse) representing edges and their MSE.\n",
    "        \"\"\"\n",
    "        # Validate image shape\n",
    "        \n",
    "        assert image.shape[0] == image.shape[1], \"Image must be square.\"\n",
    "\n",
    "        # Number of patches along one dimension\n",
    "        num_patches = image.shape[0] // patch_size\n",
    "\n",
    "        # Initialize nodes and edges\n",
    "        nodes = []\n",
    "        edges = []\n",
    "\n",
    "        # Create patches and flatten them to create node features\n",
    "        for i in range(0, image.shape[0], patch_size):\n",
    "            for j in range(0, image.shape[1], patch_size):\n",
    "                patch = image[i:i+patch_size, j:j+patch_size, :].reshape(-1)\n",
    "                nodes.append(patch)\n",
    "\n",
    "        nodes = np.array(nodes)\n",
    "\n",
    "        # Use KNN to find nearest neighbors for each node\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors+1, algorithm='ball_tree').fit(nodes)\n",
    "        distances, indices = nbrs.kneighbors(nodes)\n",
    "\n",
    "        # Calculate MSE for each pair of neighbors and create edges\n",
    "        for i in range(indices.shape[0]):\n",
    "            for j in range(1, indices.shape[1]):  # Start from 1 to skip self-connection\n",
    "                mse = mean_squared_error(nodes[i], nodes[indices[i, j]])\n",
    "                edges.append((i, indices[i, j], mse))\n",
    "\n",
    "        return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e64113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.387945Z",
     "iopub.status.busy": "2024-03-24T12:13:58.387284Z",
     "iopub.status.idle": "2024-03-24T12:13:58.396568Z",
     "shell.execute_reply": "2024-03-24T12:13:58.395709Z"
    },
    "papermill": {
     "duration": 0.01884,
     "end_time": "2024-03-24T12:13:58.398598",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.379758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuarkGluonDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, root='', transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for quarks and gluons classification.\n",
    "        \n",
    "        Parameters:\n",
    "        - image_list: A list of (125, 125, 3) numpy arrays.\n",
    "        - labels: A list of integers (0 or 1) representing the class labels for the images.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        super(QuarkGluonDataset, self).__init__(root, transform, pre_transform)\n",
    "    \n",
    "   \n",
    "    def len(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        # Convert an image to graph data\n",
    "        image = self.dataframe.iloc[idx]['X_jets']\n",
    "        image = image.transpose(1,2,0)\n",
    "        label = self.dataframe.iloc[idx]['y']\n",
    "#         print(type(image))\n",
    "        nodes, edges = image_to_graph(image)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        x = torch.tensor(nodes, dtype=torch.float)  # Node features\n",
    "        edge_index = torch.tensor([(i, j) for i, j, _ in edges], dtype=torch.long).t().contiguous()  # Edge indices\n",
    "        edge_attr = torch.tensor([mse for _, _, mse in edges], dtype=torch.float).unsqueeze(1)  # Edge attributes\n",
    "        y = torch.tensor([label], dtype=torch.long)  # Label\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fccf04fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.413107Z",
     "iopub.status.busy": "2024-03-24T12:13:58.412408Z",
     "iopub.status.idle": "2024-03-24T12:13:58.418932Z",
     "shell.execute_reply": "2024-03-24T12:13:58.418045Z"
    },
    "papermill": {
     "duration": 0.016178,
     "end_time": "2024-03-24T12:13:58.421181",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.405003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = QuarkGluonDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5b134b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.435395Z",
     "iopub.status.busy": "2024-03-24T12:13:58.434658Z",
     "iopub.status.idle": "2024-03-24T12:13:58.562793Z",
     "shell.execute_reply": "2024-03-24T12:13:58.561514Z"
    },
    "papermill": {
     "duration": 0.137887,
     "end_time": "2024-03-24T12:13:58.565270",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.427383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[25, 1875], edge_index=[2, 375], edge_attr=[375, 1], y=[1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98205431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.580371Z",
     "iopub.status.busy": "2024-03-24T12:13:58.579951Z",
     "iopub.status.idle": "2024-03-24T12:13:58.586964Z",
     "shell.execute_reply": "2024-03-24T12:13:58.585744Z"
    },
    "papermill": {
     "duration": 0.016903,
     "end_time": "2024-03-24T12:13:58.589450",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.572547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d4873a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.604299Z",
     "iopub.status.busy": "2024-03-24T12:13:58.603882Z",
     "iopub.status.idle": "2024-03-24T12:13:58.622228Z",
     "shell.execute_reply": "2024-03-24T12:13:58.621030Z"
    },
    "papermill": {
     "duration": 0.028595,
     "end_time": "2024-03-24T12:13:58.624752",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.596157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# Perform the random split\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create the DataLoaders for the train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "967bcf1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.640231Z",
     "iopub.status.busy": "2024-03-24T12:13:58.639047Z",
     "iopub.status.idle": "2024-03-24T12:13:58.644130Z",
     "shell.execute_reply": "2024-03-24T12:13:58.642975Z"
    },
    "papermill": {
     "duration": 0.015146,
     "end_time": "2024-03-24T12:13:58.646355",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.631209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a7ed5cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.661318Z",
     "iopub.status.busy": "2024-03-24T12:13:58.660946Z",
     "iopub.status.idle": "2024-03-24T12:13:58.795443Z",
     "shell.execute_reply": "2024-03-24T12:13:58.794132Z"
    },
    "papermill": {
     "duration": 0.144885,
     "end_time": "2024-03-24T12:13:58.798006",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.653121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrectedGNN(\n",
      "  (conv1): GATConv(1875, 64, heads=1)\n",
      "  (conv2): GATConv(64, 64, heads=1)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CorrectedGNN(torch.nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels):\n",
    "        super(CorrectedGNN, self).__init__()\n",
    "        self.conv1 = GATConv(node_in_channels, hidden_channels, add_self_loops=True)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        self.dropout_rate = 0.5\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch\n",
    "\n",
    "        # First GAT layer\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Second GAT layer\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Apply final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example model instantiation\n",
    "node_in_channels = 1875  # Number of node features\n",
    "edge_in_channels = 1     # Number of edge features\n",
    "hidden_channels = 64     # Hidden layer size\n",
    "model = CorrectedGNN(node_in_channels, edge_in_channels, hidden_channels)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c794857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:13:58.813130Z",
     "iopub.status.busy": "2024-03-24T12:13:58.812746Z",
     "iopub.status.idle": "2024-03-24T14:25:41.094490Z",
     "shell.execute_reply": "2024-03-24T14:25:41.093178Z"
    },
    "papermill": {
     "duration": 7902.292455,
     "end_time": "2024-03-24T14:25:41.097098",
     "exception": false,
     "start_time": "2024-03-24T12:13:58.804643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.38s/it, loss=0.539]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model: Epoch 1, Val. Acc.: 0.6709\n",
      "Epoch: 001, Train Loss: 0.6794, Val. Loss: 0.7064, Val. Acc.: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:33<00:00,  2.38s/it, loss=0.563]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: 0.6122, Val. Loss: 0.7903, Val. Acc.: 0.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:34<00:00,  2.39s/it, loss=0.383]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model: Epoch 3, Val. Acc.: 0.6816\n",
      "Epoch: 003, Train Loss: 0.5265, Val. Loss: 0.9244, Val. Acc.: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:33<00:00,  2.38s/it, loss=0.242]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.4518, Val. Loss: 1.0802, Val. Acc.: 0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.38s/it, loss=0.503]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.3569, Val. Loss: 1.3451, Val. Acc.: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.38s/it, loss=0.38]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.2921, Val. Loss: 1.4927, Val. Acc.: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:34<00:00,  2.39s/it, loss=0.286]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.2370, Val. Loss: 1.6720, Val. Acc.: 0.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.37s/it, loss=0.138]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.1739, Val. Loss: 2.1443, Val. Acc.: 0.6538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.37s/it, loss=0.383]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.1346, Val. Loss: 2.3773, Val. Acc.: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.38s/it, loss=0.0123]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.1138, Val. Loss: 2.4465, Val. Acc.: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:36<00:00,  2.41s/it, loss=0.317]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.0739, Val. Loss: 2.7276, Val. Acc.: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:33<00:00,  2.38s/it, loss=0.0178]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.0570, Val. Loss: 3.0241, Val. Acc.: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:30<00:00,  2.36s/it, loss=0.0185]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.0604, Val. Loss: 3.3549, Val. Acc.: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:31<00:00,  2.37s/it, loss=0.00353]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.0398, Val. Loss: 3.6107, Val. Acc.: 0.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.37s/it, loss=0.00448]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.0358, Val. Loss: 4.0633, Val. Acc.: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:31<00:00,  2.37s/it, loss=0.0136]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.0412, Val. Loss: 4.0764, Val. Acc.: 0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:33<00:00,  2.38s/it, loss=0.018]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.0356, Val. Loss: 4.1822, Val. Acc.: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.38s/it, loss=0.00352]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.0310, Val. Loss: 4.3316, Val. Acc.: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [05:32<00:00,  2.37s/it, loss=0.0136]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.0234, Val. Loss: 4.4898, Val. Acc.: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# Modify the train function to include loss in tqdm\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(train_loader, desc=\"Training\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Similar modifications for the test/validation function, including data transfer to the device\n",
    "def test(model, loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, 20):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "#     train_acc, _ = test(model, train_loader, criterion)\n",
    "    val_acc, val_loss = test(model, valid_loader, criterion)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Saved Best Model: Epoch {epoch}, Val. Acc.: {val_acc:.4f}\")\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val. Loss: {val_loss:.4f}, Val. Acc.: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5be819",
   "metadata": {
    "papermill": {
     "duration": 0.394187,
     "end_time": "2024-03-24T14:25:41.978211",
     "exception": false,
     "start_time": "2024-03-24T14:25:41.584024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf1c18",
   "metadata": {
    "papermill": {
     "duration": 0.389327,
     "end_time": "2024-03-24T14:25:42.756856",
     "exception": false,
     "start_time": "2024-03-24T14:25:42.367529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d75295",
   "metadata": {
    "papermill": {
     "duration": 0.494708,
     "end_time": "2024-03-24T14:25:43.645919",
     "exception": false,
     "start_time": "2024-03-24T14:25:43.151211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4628811,
     "sourceId": 7885350,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7973.838044,
   "end_time": "2024-03-24T14:25:47.360121",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-24T12:12:53.522077",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
