{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed35ecf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-24T12:10:51.295246Z",
     "iopub.status.busy": "2024-03-24T12:10:51.294853Z",
     "iopub.status.idle": "2024-03-24T12:11:01.858588Z",
     "shell.execute_reply": "2024-03-24T12:11:01.856937Z"
    },
    "papermill": {
     "duration": 10.574149,
     "end_time": "2024-03-24T12:11:01.861822",
     "exception": false,
     "start_time": "2024-03-24T12:10:51.287673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix ,roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.nn import Linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23423937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:01.875676Z",
     "iopub.status.busy": "2024-03-24T12:11:01.875062Z",
     "iopub.status.idle": "2024-03-24T12:11:31.191552Z",
     "shell.execute_reply": "2024-03-24T12:11:31.189933Z"
    },
    "papermill": {
     "duration": 29.327305,
     "end_time": "2024-03-24T12:11:31.194572",
     "exception": false,
     "start_time": "2024-03-24T12:11:01.867267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\r\n",
      "  Downloading torch_geometric-2.5.2-py3-none-any.whl.metadata (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.11.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.2.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\r\n",
      "Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.5.2\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0fc8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:31.209891Z",
     "iopub.status.busy": "2024-03-24T12:11:31.209413Z",
     "iopub.status.idle": "2024-03-24T12:11:33.263271Z",
     "shell.execute_reply": "2024-03-24T12:11:33.262026Z"
    },
    "papermill": {
     "duration": 2.064505,
     "end_time": "2024-03-24T12:11:33.266130",
     "exception": false,
     "start_time": "2024-03-24T12:11:31.201625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bcd923f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:33.281700Z",
     "iopub.status.busy": "2024-03-24T12:11:33.280355Z",
     "iopub.status.idle": "2024-03-24T12:11:34.636384Z",
     "shell.execute_reply": "2024-03-24T12:11:34.634338Z"
    },
    "papermill": {
     "duration": 1.366542,
     "end_time": "2024-03-24T12:11:34.639182",
     "exception": false,
     "start_time": "2024-03-24T12:11:33.272640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear, Sequential, ReLU, Dropout\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49386619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:34.654675Z",
     "iopub.status.busy": "2024-03-24T12:11:34.654256Z",
     "iopub.status.idle": "2024-03-24T12:11:53.990402Z",
     "shell.execute_reply": "2024-03-24T12:11:53.989341Z"
    },
    "papermill": {
     "duration": 19.346706,
     "end_time": "2024-03-24T12:11:53.993149",
     "exception": false,
     "start_time": "2024-03-24T12:11:34.646443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 25\n",
    "\n",
    "# List of Parquet file paths\n",
    "file_paths = [\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
    "    '/kaggle/input/task2-24/QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file path\n",
    "for file_path in file_paths:\n",
    "    # Create a Parquet file reader object\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    \n",
    "    # Determine the total number of rows in the file\n",
    "    total_rows = parquet_file.metadata.num_rows\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = total_rows // chunk_size + (1 if total_rows % chunk_size else 0)\n",
    "    \n",
    "    # Loop over the file in chunks\n",
    "    for chunk_index in range(num_chunks):\n",
    "        # Read a chunk of rows from the file\n",
    "        chunk = parquet_file.read_row_group(chunk_index, columns=None)\n",
    "        df = chunk.to_pandas()\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84af1b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:54.009291Z",
     "iopub.status.busy": "2024-03-24T12:11:54.007686Z",
     "iopub.status.idle": "2024-03-24T12:11:54.015108Z",
     "shell.execute_reply": "2024-03-24T12:11:54.014042Z"
    },
    "papermill": {
     "duration": 0.017949,
     "end_time": "2024-03-24T12:11:54.017612",
     "exception": false,
     "start_time": "2024-03-24T12:11:53.999663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_3d(arr):\n",
    "    vishak=[]\n",
    "    for i in range (0,3):\n",
    "        vis=np.stack(np.stack(arr)[i],axis=-1)\n",
    "        vishak.append(vis)\n",
    "    vishak=np.array(vishak)\n",
    "    return vishak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa4afdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:54.032298Z",
     "iopub.status.busy": "2024-03-24T12:11:54.031037Z",
     "iopub.status.idle": "2024-03-24T12:11:58.603786Z",
     "shell.execute_reply": "2024-03-24T12:11:58.602463Z"
    },
    "papermill": {
     "duration": 4.582898,
     "end_time": "2024-03-24T12:11:58.606563",
     "exception": false,
     "start_time": "2024-03-24T12:11:54.023665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"X_jets\"]  = data[\"X_jets\"].apply(to_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199e14ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.620946Z",
     "iopub.status.busy": "2024-03-24T12:11:58.620525Z",
     "iopub.status.idle": "2024-03-24T12:11:58.630521Z",
     "shell.execute_reply": "2024-03-24T12:11:58.629208Z"
    },
    "papermill": {
     "duration": 0.019606,
     "end_time": "2024-03-24T12:11:58.632723",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.613117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_graph(image, patch_size=25, n_neighbors=5):\n",
    "        \"\"\"\n",
    "        Convert an image to a graph of its 5x5 patches.\n",
    "\n",
    "        Parameters:\n",
    "        - image: A (125, 125, 3) numpy array.\n",
    "        - patch_size: Size of the square patches (default 5).\n",
    "        - n_neighbors: Number of neighbors for KNN (default 5).\n",
    "\n",
    "        Returns:\n",
    "        - nodes: An array of node features.\n",
    "        - edges: A list of tuples (i, j, mse) representing edges and their MSE.\n",
    "        \"\"\"\n",
    "        # Validate image shape\n",
    "        \n",
    "        assert image.shape[0] == image.shape[1], \"Image must be square.\"\n",
    "\n",
    "        # Number of patches along one dimension\n",
    "        num_patches = image.shape[0] // patch_size\n",
    "\n",
    "        # Initialize nodes and edges\n",
    "        nodes = []\n",
    "        edges = []\n",
    "\n",
    "        # Create patches and flatten them to create node features\n",
    "        for i in range(0, image.shape[0], patch_size):\n",
    "            for j in range(0, image.shape[1], patch_size):\n",
    "                patch = image[i:i+patch_size, j:j+patch_size, :].reshape(-1)\n",
    "                nodes.append(patch)\n",
    "\n",
    "        nodes = np.array(nodes)\n",
    "\n",
    "        # Use KNN to find nearest neighbors for each node\n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors+1, algorithm='ball_tree').fit(nodes)\n",
    "        distances, indices = nbrs.kneighbors(nodes)\n",
    "\n",
    "        # Calculate MSE for each pair of neighbors and create edges\n",
    "        for i in range(indices.shape[0]):\n",
    "            for j in range(1, indices.shape[1]):  # Start from 1 to skip self-connection\n",
    "                mse = mean_squared_error(nodes[i], nodes[indices[i, j]])\n",
    "                edges.append((i, indices[i, j], mse))\n",
    "\n",
    "        return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85784df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.646622Z",
     "iopub.status.busy": "2024-03-24T12:11:58.646156Z",
     "iopub.status.idle": "2024-03-24T12:11:58.656793Z",
     "shell.execute_reply": "2024-03-24T12:11:58.655550Z"
    },
    "papermill": {
     "duration": 0.02068,
     "end_time": "2024-03-24T12:11:58.659540",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.638860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuarkGluonDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, root='', transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for quarks and gluons classification.\n",
    "        \n",
    "        Parameters:\n",
    "        - image_list: A list of (125, 125, 3) numpy arrays.\n",
    "        - labels: A list of integers (0 or 1) representing the class labels for the images.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        super(QuarkGluonDataset, self).__init__(root, transform, pre_transform)\n",
    "    \n",
    "   \n",
    "    def len(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        # Convert an image to graph data\n",
    "        image = self.dataframe.iloc[idx]['X_jets']\n",
    "        image = image.transpose(1,2,0)\n",
    "        label = self.dataframe.iloc[idx]['y']\n",
    "#         print(type(image))\n",
    "        nodes, edges = image_to_graph(image)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        x = torch.tensor(nodes, dtype=torch.float)  # Node features\n",
    "        edge_index = torch.tensor([(i, j) for i, j, _ in edges], dtype=torch.long).t().contiguous()  # Edge indices\n",
    "        edge_attr = torch.tensor([mse for _, _, mse in edges], dtype=torch.float).unsqueeze(1)  # Edge attributes\n",
    "        y = torch.tensor([label], dtype=torch.long)  # Label\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e82dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.674111Z",
     "iopub.status.busy": "2024-03-24T12:11:58.673348Z",
     "iopub.status.idle": "2024-03-24T12:11:58.681053Z",
     "shell.execute_reply": "2024-03-24T12:11:58.680017Z"
    },
    "papermill": {
     "duration": 0.017971,
     "end_time": "2024-03-24T12:11:58.683591",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.665620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = QuarkGluonDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b779043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.697428Z",
     "iopub.status.busy": "2024-03-24T12:11:58.697061Z",
     "iopub.status.idle": "2024-03-24T12:11:58.784771Z",
     "shell.execute_reply": "2024-03-24T12:11:58.783295Z"
    },
    "papermill": {
     "duration": 0.097555,
     "end_time": "2024-03-24T12:11:58.787310",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.689755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[25, 1875], edge_index=[2, 125], edge_attr=[125, 1], y=[1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca6f35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.803378Z",
     "iopub.status.busy": "2024-03-24T12:11:58.802981Z",
     "iopub.status.idle": "2024-03-24T12:11:58.809950Z",
     "shell.execute_reply": "2024-03-24T12:11:58.808840Z"
    },
    "papermill": {
     "duration": 0.017445,
     "end_time": "2024-03-24T12:11:58.812371",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.794926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea02f5fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.826398Z",
     "iopub.status.busy": "2024-03-24T12:11:58.826007Z",
     "iopub.status.idle": "2024-03-24T12:11:58.844197Z",
     "shell.execute_reply": "2024-03-24T12:11:58.842697Z"
    },
    "papermill": {
     "duration": 0.028561,
     "end_time": "2024-03-24T12:11:58.847108",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.818547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# Perform the random split\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create the DataLoaders for the train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ed94fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.861194Z",
     "iopub.status.busy": "2024-03-24T12:11:58.860814Z",
     "iopub.status.idle": "2024-03-24T12:11:58.866344Z",
     "shell.execute_reply": "2024-03-24T12:11:58.864944Z"
    },
    "papermill": {
     "duration": 0.016291,
     "end_time": "2024-03-24T12:11:58.869599",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.853308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cd566c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:58.883614Z",
     "iopub.status.busy": "2024-03-24T12:11:58.883158Z",
     "iopub.status.idle": "2024-03-24T12:11:59.021939Z",
     "shell.execute_reply": "2024-03-24T12:11:59.021005Z"
    },
    "papermill": {
     "duration": 0.148483,
     "end_time": "2024-03-24T12:11:59.024229",
     "exception": false,
     "start_time": "2024-03-24T12:11:58.875746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CorrectedGNN(\n",
      "  (conv1): GATConv(1875, 64, heads=1)\n",
      "  (conv2): GATConv(64, 64, heads=1)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CorrectedGNN(torch.nn.Module):\n",
    "    def __init__(self, node_in_channels, edge_in_channels, hidden_channels):\n",
    "        super(CorrectedGNN, self).__init__()\n",
    "        self.conv1 = GATConv(node_in_channels, hidden_channels, add_self_loops=True)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels, add_self_loops=True)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "        self.dropout_rate = 0.5\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        batch = data.batch\n",
    "\n",
    "        # First GAT layer\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Second GAT layer\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Global mean pooling\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Apply final classifier\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example model instantiation\n",
    "node_in_channels = 1875  # Number of node features\n",
    "edge_in_channels = 1     # Number of edge features\n",
    "hidden_channels = 64     # Hidden layer size\n",
    "model = CorrectedGNN(node_in_channels, edge_in_channels, hidden_channels)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0dd3d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T12:11:59.039821Z",
     "iopub.status.busy": "2024-03-24T12:11:59.039348Z",
     "iopub.status.idle": "2024-03-24T13:04:02.790130Z",
     "shell.execute_reply": "2024-03-24T13:04:02.788823Z"
    },
    "papermill": {
     "duration": 3123.762463,
     "end_time": "2024-03-24T13:04:02.793378",
     "exception": false,
     "start_time": "2024-03-24T12:11:59.030915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:12<00:00,  1.06it/s, loss=0.716]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model: Epoch 1, Val. Acc.: 0.6502\n",
      "Epoch: 001, Train Loss: 0.6747, Val. Loss: 0.6509, Val. Acc.: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:11<00:00,  1.07it/s, loss=0.764]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model: Epoch 2, Val. Acc.: 0.6529\n",
      "Epoch: 002, Train Loss: 0.6179, Val. Loss: 0.6409, Val. Acc.: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:09<00:00,  1.08it/s, loss=0.626]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: 0.5491, Val. Loss: 0.6666, Val. Acc.: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:11<00:00,  1.06it/s, loss=0.193]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: 0.4685, Val. Loss: 0.7088, Val. Acc.: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:12<00:00,  1.06it/s, loss=0.237]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: 0.3851, Val. Loss: 0.7839, Val. Acc.: 0.6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:11<00:00,  1.06it/s, loss=0.279]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: 0.3030, Val. Loss: 0.8936, Val. Acc.: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.184]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: 0.2759, Val. Loss: 0.9411, Val. Acc.: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.0683]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: 0.1916, Val. Loss: 1.0604, Val. Acc.: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.201]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: 0.1483, Val. Loss: 1.1669, Val. Acc.: 0.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.0901]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 0.1109, Val. Loss: 1.3023, Val. Acc.: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.0469]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: 0.1016, Val. Loss: 1.3563, Val. Acc.: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:16<00:00,  1.03it/s, loss=0.0305]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: 0.1070, Val. Loss: 1.4630, Val. Acc.: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:13<00:00,  1.05it/s, loss=0.0585]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: 0.0689, Val. Loss: 1.5963, Val. Acc.: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:13<00:00,  1.05it/s, loss=0.0904]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: 0.0580, Val. Loss: 1.5971, Val. Acc.: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:11<00:00,  1.07it/s, loss=0.0145]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: 0.0906, Val. Loss: 1.6821, Val. Acc.: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:12<00:00,  1.06it/s, loss=0.0114]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: 0.0438, Val. Loss: 1.8080, Val. Acc.: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:12<00:00,  1.05it/s, loss=0.165]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: 0.0428, Val. Loss: 1.8286, Val. Acc.: 0.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:10<00:00,  1.07it/s, loss=0.0176]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: 0.0427, Val. Loss: 1.8692, Val. Acc.: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 140/140 [02:13<00:00,  1.05it/s, loss=0.0259]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: 0.0302, Val. Loss: 1.9645, Val. Acc.: 0.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Move the model to the chosen device\n",
    "model.to(device)\n",
    "\n",
    "# Modify the train function to include loss in tqdm\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(train_loader, desc=\"Training\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Similar modifications for the test/validation function, including data transfer to the device\n",
    "def test(model, loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, 20):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "#     train_acc, _ = test(model, train_loader, criterion)\n",
    "    val_acc, val_loss = test(model, valid_loader, criterion)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Saved Best Model: Epoch {epoch}, Val. Acc.: {val_acc:.4f}\")\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val. Loss: {val_loss:.4f}, Val. Acc.: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa46404",
   "metadata": {
    "papermill": {
     "duration": 0.421678,
     "end_time": "2024-03-24T13:04:03.701347",
     "exception": false,
     "start_time": "2024-03-24T13:04:03.279669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9409c",
   "metadata": {
    "papermill": {
     "duration": 0.412041,
     "end_time": "2024-03-24T13:04:04.556392",
     "exception": false,
     "start_time": "2024-03-24T13:04:04.144351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a94ae",
   "metadata": {
    "papermill": {
     "duration": 0.472276,
     "end_time": "2024-03-24T13:04:05.467406",
     "exception": false,
     "start_time": "2024-03-24T13:04:04.995130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4628811,
     "sourceId": 7885350,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3200.458791,
   "end_time": "2024-03-24T13:04:08.295132",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-24T12:10:47.836341",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
